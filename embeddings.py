import torch
import numpy
from tokenizers import vocabs

'''
this is a library that is trained on a yoruba dataset of about 80 million tokens 
that helps converts yoruba word to it's corresponding vectors which however helps to 
capture similarities in the text.
'''


with open('the-verdict.txt', 'r') as file:
    raw_text = file.read()








